# -*- coding: utf-8 -*-
"""task9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AW5J96F7VrnbxJASEwQ0nJQVGItP7Vru

### Step 1: Load the Titanic dataset from the provided CSV files
"""

import pandas as pd
from IPython.display import display

# Load datasets
train_data = pd.read_csv("project/task9/train.csv")
test = pd.read_csv("project/task9/test.csv")

# Display first few rows of the training set
train_data.head()

"""### Step 2: Data Preprocessing (Data Cleaning)
- Check for missing values and handle them.
- Convert categorical columns into numeric (e.g., `Sex`, `Embarked`).
- Drop irrelevant features if necessary (e.g., `Name`, `Ticket`).
"""


# Check the column names in train_data
print(train_data.columns)

# Checking for missing values
train_data.isnull().sum()

# Fill missing Age with the median
train_data["Age"] = train_data["Age"].fillna(
    train_data["Age"].median()
)  # Reassign to avoid inplace warning

# Fill missing Embarked with the most frequent value
train_data["Embarked"] = train_data["Embarked"].fillna(
    train_data["Embarked"].mode()[0]
)  # Reassign to avoid inplace warning

# Dropping columns that are unlikely to help in classification
# Check if the columns exist before dropping
columns_to_drop = ["Name", "Ticket", "Cabin"]
existing_columns_to_drop = [col for col in columns_to_drop if col in train_data.columns]
train_data = train_data.drop(
    existing_columns_to_drop, axis=1
)  # Reassign to avoid inplace warning

# Convert categorical variables to numeric
train_data["Sex"] = train_data["Sex"].map({"male": 0, "female": 1})
train_data["Embarked"] = train_data["Embarked"].map({"C": 0, "Q": 1, "S": 2})

# Display the first few rows of the cleaned data
train_data.head()

"""### Step 3: Exploratory Data Analysis (EDA)
Perform some initial visualizations to understand the dataset.

"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns  # type: ignore
import matplotlib.pyplot as plt

# Ensuring plots are displayed in the notebook (only needed in some environments like Jupyter/Colab)
# %matplotlib inline

# Checking for missing values in the dataset
print("Missing values in the training dataset:")
print(train_data.isnull().sum())  # Make sure to print the result

# Checking basic statistics (mean, std, min, max) for numerical features
print("Statistical summary for numerical columns in the training dataset:")
print(train_data.describe())  # Make sure to print the result

# Visualizing the distribution of features
plt.figure(figsize=(10, 6))

# Age distribution
sns.histplot(train_data["Age"], kde=True, color="blue", bins=20)
plt.title("Age Distribution")
plt.show()

# Fare distribution
sns.histplot(train_data["Fare"], kde=True, color="green", bins=20)
plt.title("Fare Distribution")
plt.show()

# Class distribution (Survived vs. Not Survived)
sns.countplot(data=train_data, x="Survived", palette="pastel")
plt.title("Class Distribution (Survived vs Not Survived)")
plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(train_data.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Visualizing relationships between features
sns.pairplot(train_data[["Age", "Fare", "Pclass", "Survived"]], hue="Survived")
plt.show()

# Visualizing survival rates by different features (e.g., Sex, Pclass, Embarked)
plt.figure(figsize=(10, 6))
sns.barplot(data=train_data, x="Pclass", y="Survived", palette="Blues")
plt.title("Survival Rate by Pclass")
plt.show()

"""### Step 4: Feature Engineering
Create new features or transform existing ones to improve model performance.

"""

# Check if the 'SibSp' and 'Parch' columns are present
if "SibSp" in train_data.columns and "Parch" in train_data.columns:
    # Create new feature 'FamilySize' by combining SibSp and Parch
    train_data["FamilySize"] = train_data["SibSp"] + train_data["Parch"] + 1

    # Drop 'SibSp' and 'Parch' as they are now combined in 'FamilySize'
    train_data.drop(["SibSp", "Parch"], axis=1, inplace=True)
else:
    print("Columns 'SibSp' and/or 'Parch' are missing from the dataset.")

# Display the first few rows to verify the changes
train_data.head()

"""### Step 5: Model Training
Now, we can proceed to implement a classification model. I'll use a decision tree and logistic regression as examples of classifiers.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split  # type: ignore
from sklearn.tree import DecisionTreeClassifier  # type: ignore
from sklearn.linear_model import LogisticRegression  # type: ignore
from sklearn.metrics import accuracy_score, classification_report  # type: ignore

# Load and preprocess the data (assuming train_data is a pandas DataFrame)
# Split features and target
X = train_data.drop("Survived", axis=1)
y = train_data["Survived"]

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Decision Tree implementation using sklearn
dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)
dt_model.fit(X_train, y_train)
dt_predictions = dt_model.predict(X_test)

# Logistic Regression implementation using sklearn
log_reg_model = LogisticRegression(max_iter=1000, random_state=42)
log_reg_model.fit(X_train, y_train)
log_predictions = log_reg_model.predict(X_test)

# Evaluate performance
dt_accuracy = accuracy_score(y_test, dt_predictions)
log_accuracy = accuracy_score(y_test, log_predictions)

print("Decision Tree Metrics:")
print(classification_report(y_test, dt_predictions))
print(f"Accuracy: {dt_accuracy:.4f}\n")

print("Logistic Regression Metrics:")
print(classification_report(y_test, log_predictions))
print(f"Accuracy: {log_accuracy:.4f}\n")

# Explanation
print("Model Evaluation Summary:")
print("- Decision Tree Accuracy:", dt_accuracy)
print("- Logistic Regression Accuracy:", log_accuracy)

print("\nPossible reasons for performance differences:")
print("- Limited feature engineering.")
print("- Lack of hyperparameter tuning.")
print("- Small dataset or high variance in the data.")

"""### Step 6: Evaluation
Evaluate the models using precision, recall, and accuracy metrics. I'll compute these metrics manually to compare with the results from the lecture.

"""

import numpy as np


def evaluate_metrics(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))

    # Avoid division by zero
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0

    return precision, recall, accuracy


log_reg_model = LogisticRegression(max_iter=1000, random_state=42)
log_reg_model.fit(X_train, y_train)
log_predictions = log_reg_model.predict(X_test)

# Evaluate logistic regression manually
log_precision, log_recall, log_accuracy = evaluate_metrics(y_test, log_predictions)

# Display evaluation metrics
display(f"Logistic Regression Precision: {log_precision}")
display(f"Logistic Regression Recall: {log_recall}")
display(f"Logistic Regression Accuracy: {log_accuracy}")

# Plot the distribution of predictions
plt.hist(log_predictions, bins=2, align="mid", rwidth=0.8)
plt.title("Distribution of Logistic Regression Predictions")
plt.xlabel("Predicted Class")
plt.ylabel("Frequency")
plt.show()

# Compare Logistic Regression and Decision Tree
print(f"Decision Tree Accuracy: {dt_accuracy}")
print(f"Logistic Regression Accuracy: {log_accuracy}")
